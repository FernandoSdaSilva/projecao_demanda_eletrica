{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from load import load_data\n",
    "from load import series_to_supervised\n",
    "from load import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from load import get_measures\n",
    "import lightgbm as lgb\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 5 # tamanho das figuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = np.asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = lgb.LGBMRegressor(objective='regression', n_estimators=1000)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict([testX])\n",
    "\treturn yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # split test row into input and output columns\n",
    "        testX, testy = test[i, :-1], test[i, -1]\n",
    "        # fit model on history and make a prediction\n",
    "        yhat = lightgbm_forecast(history, testX)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "        # summarize progress\n",
    "        print('>expected = %.1f, predicted = %.1f' % (testy, yhat))\n",
    "    # estimate prediction error\n",
    "    mae = mean_absolute_error(test[:, -1], predictions)\n",
    "    mape = mean_absolute_percentage_error(test[:, -1], predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(test[:, -1], predictions))    \n",
    "    return mae, mape, rmse, test[:, -1], predictions\n",
    "\n",
    "def multi_step_forecast(data, lag, n):\n",
    "    n_test = outs = n\n",
    "    #data = series_to_supervised(values, n_in = lag, n_out = outs, dropnan=False)\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    train.dropna(inplace = True)\n",
    "    response_vars = data.columns[-(outs):]\n",
    "    predictions = list()\n",
    "    for h, response in enumerate(response_vars):\n",
    "        cols = [x for x in data.columns[:lag]]\n",
    "        cols.append(response)\n",
    "        data_ = train[cols]\n",
    "        nrows = data_.shape[0]\n",
    "        data_ = data_.iloc[:nrows-h, :] \n",
    "        data_X, data_y = data_.iloc[:, :-1], data_.iloc[:, -1]\n",
    "        model = lgb.LGBMRegressor(objective='regression', n_estimators=1000)\n",
    "        model.fit(data_X, data_y)\n",
    "        testX, testy = test.reset_index(drop=True).loc[0, :\"var1(t-1)\"], test.reset_index(drop=True).loc[0, response]\n",
    "        pred = model.predict([testX])[0]\n",
    "        print(f\"Predicting {response}\\n  > expected: {testy}, predicted: {pred}\")\n",
    "        predictions.append(pred)\n",
    "    measures = get_measures(pd.Series(predictions), test[\"var1(t)\"])\n",
    "    df_measures = pd.DataFrame([measures])\n",
    "    return predictions, df_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = load_data()\n",
    "df_weather = pd.read_csv(\"../data/weather_daily_data.csv\", parse_dates=[\"DATA\"])\n",
    "# gets the same period for both dataframes\n",
    "df_weather = df_weather[df_weather.DATA.isin(df_load.index)]\n",
    "df_load = df_load[df_weather.DATA.min():df_weather.DATA.max()] \n",
    "\n",
    "df_load_2 = df_load.reset_index()\n",
    "df_merged = pd.merge(df_weather, df_load_2, left_on = \"DATA\", right_on = \"date\", how = \"outer\")\n",
    "df_merged.drop(\"date\", axis = 1, inplace = True)\n",
    "\n",
    "df_merged.dropna(how = \"all\", inplace = True)\n",
    "df_merged.sort_values(by = \"DATA\", inplace = True)\n",
    "df_merged.load_mwmed = df_merged.load_mwmed.interpolate(method=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-15)_PRECIPITACAO_PR</th>\n",
       "      <th>var1(t-14)_PRECIPITACAO_PR</th>\n",
       "      <th>var1(t-13)_PRECIPITACAO_PR</th>\n",
       "      <th>var1(t-12)_PRECIPITACAO_PR</th>\n",
       "      <th>var1(t-11)_PRECIPITACAO_PR</th>\n",
       "      <th>var1(t-10)_PRECIPITACAO_PR</th>\n",
       "      <th>var1(t-9)_PRECIPITACAO_PR</th>\n",
       "      <th>var1(t-8)_PRECIPITACAO_PR</th>\n",
       "      <th>var1(t-7)_PRECIPITACAO_PR</th>\n",
       "      <th>var1(t-6)_PRECIPITACAO_PR</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t+5)</th>\n",
       "      <th>var1(t+6)</th>\n",
       "      <th>var1(t+7)</th>\n",
       "      <th>var1(t+8)</th>\n",
       "      <th>var1(t+9)</th>\n",
       "      <th>var1(t+10)</th>\n",
       "      <th>var1(t+11)</th>\n",
       "      <th>var1(t+12)</th>\n",
       "      <th>var1(t+13)</th>\n",
       "      <th>var1(t+14)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6930.564167</td>\n",
       "      <td>9086.430417</td>\n",
       "      <td>9437.825000</td>\n",
       "      <td>9535.760417</td>\n",
       "      <td>9946.955417</td>\n",
       "      <td>9684.091667</td>\n",
       "      <td>8194.232083</td>\n",
       "      <td>6997.824167</td>\n",
       "      <td>9407.491250</td>\n",
       "      <td>9897.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9086.430417</td>\n",
       "      <td>9437.825000</td>\n",
       "      <td>9535.760417</td>\n",
       "      <td>9946.955417</td>\n",
       "      <td>9684.091667</td>\n",
       "      <td>8194.232083</td>\n",
       "      <td>6997.824167</td>\n",
       "      <td>9407.491250</td>\n",
       "      <td>9897.250000</td>\n",
       "      <td>9960.365417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9437.825000</td>\n",
       "      <td>9535.760417</td>\n",
       "      <td>9946.955417</td>\n",
       "      <td>9684.091667</td>\n",
       "      <td>8194.232083</td>\n",
       "      <td>6997.824167</td>\n",
       "      <td>9407.491250</td>\n",
       "      <td>9897.250000</td>\n",
       "      <td>9960.365417</td>\n",
       "      <td>9751.891667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9535.760417</td>\n",
       "      <td>9946.955417</td>\n",
       "      <td>9684.091667</td>\n",
       "      <td>8194.232083</td>\n",
       "      <td>6997.824167</td>\n",
       "      <td>9407.491250</td>\n",
       "      <td>9897.250000</td>\n",
       "      <td>9960.365417</td>\n",
       "      <td>9751.891667</td>\n",
       "      <td>9676.098333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9946.955417</td>\n",
       "      <td>9684.091667</td>\n",
       "      <td>8194.232083</td>\n",
       "      <td>6997.824167</td>\n",
       "      <td>9407.491250</td>\n",
       "      <td>9897.250000</td>\n",
       "      <td>9960.365417</td>\n",
       "      <td>9751.891667</td>\n",
       "      <td>9676.098333</td>\n",
       "      <td>8231.710417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5260</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>73.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>2.2</td>\n",
       "      <td>73.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5262</th>\n",
       "      <td>73.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5265 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var1(t-15)_PRECIPITACAO_PR  var1(t-14)_PRECIPITACAO_PR  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                         NaN   \n",
       "3                            NaN                         NaN   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "5260                         5.2                         2.2   \n",
       "5261                         2.2                        73.2   \n",
       "5262                        73.2                        15.0   \n",
       "5263                        15.0                         1.6   \n",
       "5264                         1.6                         0.2   \n",
       "\n",
       "      var1(t-13)_PRECIPITACAO_PR  var1(t-12)_PRECIPITACAO_PR  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                         NaN   \n",
       "3                            NaN                         NaN   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "5260                        73.2                        15.0   \n",
       "5261                        15.0                         1.6   \n",
       "5262                         1.6                         0.2   \n",
       "5263                         0.2                         0.2   \n",
       "5264                         0.2                         1.4   \n",
       "\n",
       "      var1(t-11)_PRECIPITACAO_PR  var1(t-10)_PRECIPITACAO_PR  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                         NaN   \n",
       "3                            NaN                         NaN   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "5260                         1.6                         0.2   \n",
       "5261                         0.2                         0.2   \n",
       "5262                         0.2                         1.4   \n",
       "5263                         1.4                         0.4   \n",
       "5264                         0.4                         0.2   \n",
       "\n",
       "      var1(t-9)_PRECIPITACAO_PR  var1(t-8)_PRECIPITACAO_PR  \\\n",
       "0                           NaN                        NaN   \n",
       "1                           NaN                        NaN   \n",
       "2                           NaN                        NaN   \n",
       "3                           NaN                        NaN   \n",
       "4                           NaN                        NaN   \n",
       "...                         ...                        ...   \n",
       "5260                        0.2                        1.4   \n",
       "5261                        1.4                        0.4   \n",
       "5262                        0.4                        0.2   \n",
       "5263                        0.2                        0.0   \n",
       "5264                        0.0                        0.0   \n",
       "\n",
       "      var1(t-7)_PRECIPITACAO_PR  var1(t-6)_PRECIPITACAO_PR  ...    var1(t+5)  \\\n",
       "0                           NaN                        NaN  ...  6930.564167   \n",
       "1                           NaN                        NaN  ...  9086.430417   \n",
       "2                           NaN                        NaN  ...  9437.825000   \n",
       "3                           NaN                        NaN  ...  9535.760417   \n",
       "4                           NaN                        NaN  ...  9946.955417   \n",
       "...                         ...                        ...  ...          ...   \n",
       "5260                        0.4                        0.2  ...          NaN   \n",
       "5261                        0.2                        0.0  ...          NaN   \n",
       "5262                        0.0                        0.0  ...          NaN   \n",
       "5263                        0.0                        0.0  ...          NaN   \n",
       "5264                        0.0                        0.4  ...          NaN   \n",
       "\n",
       "        var1(t+6)    var1(t+7)    var1(t+8)    var1(t+9)   var1(t+10)  \\\n",
       "0     9086.430417  9437.825000  9535.760417  9946.955417  9684.091667   \n",
       "1     9437.825000  9535.760417  9946.955417  9684.091667  8194.232083   \n",
       "2     9535.760417  9946.955417  9684.091667  8194.232083  6997.824167   \n",
       "3     9946.955417  9684.091667  8194.232083  6997.824167  9407.491250   \n",
       "4     9684.091667  8194.232083  6997.824167  9407.491250  9897.250000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5260          NaN          NaN          NaN          NaN          NaN   \n",
       "5261          NaN          NaN          NaN          NaN          NaN   \n",
       "5262          NaN          NaN          NaN          NaN          NaN   \n",
       "5263          NaN          NaN          NaN          NaN          NaN   \n",
       "5264          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       var1(t+11)   var1(t+12)   var1(t+13)   var1(t+14)  \n",
       "0     8194.232083  6997.824167  9407.491250  9897.250000  \n",
       "1     6997.824167  9407.491250  9897.250000  9960.365417  \n",
       "2     9407.491250  9897.250000  9960.365417  9751.891667  \n",
       "3     9897.250000  9960.365417  9751.891667  9676.098333  \n",
       "4     9960.365417  9751.891667  9676.098333  8231.710417  \n",
       "...           ...          ...          ...          ...  \n",
       "5260          NaN          NaN          NaN          NaN  \n",
       "5261          NaN          NaN          NaN          NaN  \n",
       "5262          NaN          NaN          NaN          NaN  \n",
       "5263          NaN          NaN          NaN          NaN  \n",
       "5264          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5265 rows x 300 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag = 15\n",
    "outs = n_test = 15\n",
    "df_load_3 = df_merged.load_mwmed\n",
    "df_load_3.index = df_merged.DATA\n",
    "df_load_3 = df_load_3[\"2008-01-01\":]\n",
    "values = df_load_3.values.tolist()\n",
    "data1 = series_to_supervised(values, n_in = lag, n_out=outs, dropnan=False)\n",
    "data2 = pd.DataFrame()\n",
    "df_weather.set_index(\"DATA\", inplace=True) # TESTE: MAPE PASSOU DE 3,2 PARA 3,0\n",
    "df_weather = df_weather[\"2008-01-01\":] \n",
    "for col in df_weather.columns:\n",
    "    if col == \"DATA\":\n",
    "        continue\n",
    "    else:\n",
    "        values = df_weather[col].values.tolist()\n",
    "        df_ = series_to_supervised(values, n_in = lag, dropnan=False)\n",
    "        df_.drop(\"var1(t)\", axis = 1, inplace = True) # the response variable is the load dataframe\n",
    "        df_.columns = [f\"{x}_{col}\" for x in df_.columns]\n",
    "        data2 = pd.concat([data2, df_], axis = 1)\n",
    "df_weather_load = pd.concat([data2, data1], axis = 1)\n",
    "df_weather_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEM FUNÇÃO\n",
    "#n_test = outs = 10 # com 10 funciona, com outros horizontes não\n",
    "train, test = train_test_split(df_weather_load, n_test)\n",
    "train.dropna(inplace = True)\n",
    "response_vars = df_weather_load.columns[-(outs):]\n",
    "predictions = list()\n",
    "for h, response in enumerate(response_vars):\n",
    "    cols = [x for x in df_weather_load.columns[:df_weather_load.shape[1] - outs]]\n",
    "    print(cols)\n",
    "    cols.append(response)\n",
    "    data_ = train[cols]\n",
    "    nrows = data_.shape[0]\n",
    "    data_ = data_.iloc[:nrows-h, :] \n",
    "    data_X, data_y = data_.iloc[:, :-1], data_.iloc[:, -1]\n",
    "    model = lgb.LGBMRegressor(objective='regression', n_estimators=1000)\n",
    "    model.fit(data_X, data_y)\n",
    "    testX, testy = test.reset_index(drop=True).loc[0, :\"var1(t-1)\"], test.reset_index(drop=True).loc[0, response]\n",
    "    pred = model.predict([testX])[0]\n",
    "    print(f\"Predicting {response}\\n  > expected: {testy}, predicted: {pred}\")\n",
    "    predictions.append(pred)\n",
    "measures = get_measures(pd.Series(predictions), test[\"var1(t)\"])\n",
    "df_measures = pd.DataFrame([measures])\n",
    "print(df_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_forecast(data, n):\n",
    "    n_test = outs = n\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    train.dropna(inplace = True)\n",
    "    response_vars = data.columns[-(outs):]\n",
    "    predictions = list()\n",
    "    for h, response in enumerate(response_vars):\n",
    "        cols = [x for x in data.columns[:data.shape[1] - outs]]\n",
    "        cols.append(response)\n",
    "        data_ = train[cols]\n",
    "        nrows = data_.shape[0]\n",
    "        data_ = data_.iloc[:nrows-h, :] \n",
    "        data_X, data_y = data_.iloc[:, :-1], data_.iloc[:, -1]\n",
    "        model = lgb.LGBMRegressor(objective='regression', n_estimators=1000)\n",
    "        model.fit(data_X, data_y)\n",
    "        #teste = train.loc[:, :\"var1(t-1)\"].iloc[-1,:] # t + 3 (observado = 12.054,20)\n",
    "        testX, testy = test.reset_index(drop=True).loc[0, :\"var1(t-1)\"], test.reset_index(drop=True).loc[0, response]\n",
    "        pred = model.predict([testX])[0]\n",
    "        print(f\"Predicting {response}\\n  > expected: {testy}, predicted: {pred}\")\n",
    "        predictions.append(pred)\n",
    "    measures = get_measures(pd.Series(predictions), test[\"var1(t)\"])\n",
    "    df_measures = pd.DataFrame([measures])\n",
    "    #return predictions\n",
    "    return df_measures\n",
    "\n",
    "multi_step_forecast(df_weather_load, outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting for cv 15...\n"
     ]
    }
   ],
   "source": [
    "lag = 15\n",
    "outs = n_test = horz = 15\n",
    "df_load_3 = df_merged.load_mwmed\n",
    "df_load_3.index = df_merged.DATA\n",
    "df_load_3 = df_load_3[\"2008-01-01\":]\n",
    "values = df_load_3.values.tolist()\n",
    "data1 = series_to_supervised(values, n_in = lag, n_out=outs, dropnan=False)\n",
    "data2 = pd.DataFrame()\n",
    "df_weather = df_weather[\"2008-01-01\":] \n",
    "for col in df_weather.columns:\n",
    "    if col == \"DATA\":\n",
    "        continue\n",
    "    else:\n",
    "        values = df_weather[col].values.tolist()\n",
    "        df_ = series_to_supervised(values, n_in = lag, dropnan=False)\n",
    "        df_.drop(\"var1(t)\", axis = 1, inplace = True) # the response variable is the load dataframe\n",
    "        df_.columns = [f\"{x}_{col}\" for x in df_.columns]\n",
    "        data2 = pd.concat([data2, df_], axis = 1)\n",
    "df_weather_load = pd.concat([data2, data1], axis = 1)\n",
    "\n",
    "\n",
    "folds = 15 #partições\n",
    "rows = df_weather_load.shape[0]\n",
    "out = defaultdict(dict)\n",
    "for fold in range(folds,0,-1):\n",
    "    slide = rows-((fold-1)*horz)\n",
    "    df_cv = df_weather_load.iloc[:slide,:]\n",
    "    #print(df_cv.tail())\n",
    "    \n",
    "    train, test = train_test_split(df_cv, n_test)\n",
    "    train.dropna(inplace = True)\n",
    "    response_vars = df_weather_load.columns[-(outs):]\n",
    "    print(f\"predicting for cv {fold}...\")\n",
    "    predictions = list()\n",
    "    for h, response in enumerate(response_vars):\n",
    "        cols = [x for x in df_cv.columns[:df_cv.shape[1] - outs]]\n",
    "        cols.append(response)\n",
    "        data_ = train[cols]\n",
    "        nrows = data_.shape[0]\n",
    "        data_ = data_.iloc[:nrows-h, :] \n",
    "        data_X, data_y = data_.iloc[:, :-1], data_.iloc[:, -1]\n",
    "        model = lgb.LGBMRegressor(objective='regression', n_estimators=1000)\n",
    "        model.fit(data_X, data_y)\n",
    "        #print(data_X)\n",
    "        testX, testy = test.reset_index(drop=True).loc[0, :\"var1(t-1)\"], test.reset_index(drop=True).loc[0, response]\n",
    "        pred = model.predict([testX])[0]\n",
    "        print(f\"\\tPredicting {response}\\n\\t\\t> expected: {testy}, predicted: {pred}\")\n",
    "        predictions.append(pred)\n",
    "    out[f\"cv_{fold}\"][\"pred\"] = predictions\n",
    "    out[f\"cv_{fold}\"][\"test\"] = test[\"var1(t)\"].to_list()\n",
    "d = dict(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv_1': {'pred': [11742.29490159845,\n",
       "   11752.398105879569,\n",
       "   11673.18263280014,\n",
       "   11756.246350118126,\n",
       "   10086.618251221176,\n",
       "   9414.412437259482,\n",
       "   11647.149970102593,\n",
       "   11914.721892459947,\n",
       "   11408.0590723506,\n",
       "   11993.182060853731,\n",
       "   11603.84333900538,\n",
       "   10317.489987196555,\n",
       "   9163.67476409575,\n",
       "   11211.218489322331,\n",
       "   11729.157162021822],\n",
       "  'test': [11964.909375,\n",
       "   12269.051375,\n",
       "   12021.41545833,\n",
       "   11802.52645833,\n",
       "   10256.970375,\n",
       "   8938.579125,\n",
       "   11713.10433333,\n",
       "   12054.19504167,\n",
       "   12186.721375,\n",
       "   12482.52370833,\n",
       "   12520.80383333,\n",
       "   10525.490875,\n",
       "   9074.21125,\n",
       "   11648.70958333,\n",
       "   12162.75679167]}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'erro': 2836397.641487, 'mae': 355.927546, 'mse': 189093.176099, 'rmse': 434.848452, 'mape': 0.030654, 'smape': 3.115692}\n"
     ]
    }
   ],
   "source": [
    "mapes = []\n",
    "for x in d:\n",
    "    meas = get_measures(pd.Series(d[x][\"pred\"]),pd.Series(d[x][\"test\"]))\n",
    "    print(meas)\n",
    "    mapes.append(meas[\"mape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030654"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
