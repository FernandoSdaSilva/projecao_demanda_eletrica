{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script com foco no processo de forecast com previsão multi-step. <br>Método: direct prediction (ver https://machinelearningmastery.com/multi-step-time-series-forecasting/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=fG8H-0rb0mY\n",
    "#https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "#lgb.__version__\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight') # estilo dos gráficos\n",
    "rcParams['figure.figsize'] = 15, 5 # tamanho das figuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Função para ler e transformar os dados já presentes no diretório especificado\n",
    "    \"\"\"\n",
    "    path = \"../data/daily_load.csv\"\n",
    "    df_load = pd.read_csv(path, parse_dates = [\"date\"])\n",
    "    df_load2 = df_load[df_load[\"id_reg\"] == \"S\"]           # região sul\n",
    "    df_load3 = df_load2[df_load2[\"date\"] <= '2022-05-31']  # data de corte\n",
    "    df_load4 = df_load3[[\"date\", \"load_mwmed\"]].set_index(\"date\")\n",
    "    return df_load4\n",
    "\n",
    "def train_test_split(data, n_test):\n",
    "    \"\"\"\n",
    "    Função para partir or dados em treino e teste\n",
    "    \"\"\"\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        train, test = data.iloc[:-n_test, :], data.iloc[-n_test:, :]\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        train, test = data[:-n_test, :], data[-n_test:, :]\n",
    "    return train, test\n",
    "\n",
    "# https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n",
    "\n",
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in = 1, n_out = 1, dropnan = True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis = 1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace = True)\n",
    "    return agg\n",
    "\n",
    "def lightgbm_forecast(train, testX):\n",
    "\t# transform list into array\n",
    "\ttrain = np.asarray(train)\n",
    "\t# split into input and output columns\n",
    "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
    "\t# fit model\n",
    "\tmodel = lgb.LGBMRegressor(objective='regression', n_estimators=1000)\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make a one-step prediction\n",
    "\tyhat = model.predict([testX])\n",
    "\treturn yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # split test row into input and output columns\n",
    "        testX, testy = test[i, :-1], test[i, -1]\n",
    "        # fit model on history and make a prediction\n",
    "        yhat = lightgbm_forecast(history, testX)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "        # summarize progress\n",
    "        print('>expected = %.1f, predicted = %.1f' % (testy, yhat))\n",
    "    # estimate prediction error\n",
    "    mae = mean_absolute_error(test[:, -1], predictions)\n",
    "    mape = mean_absolute_percentage_error(test[:, -1], predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(test[:, -1], predictions))    \n",
    "    return mae, mape, rmse, test[:, -1], predictions\n",
    "\n",
    "def get_measures(forecast, test):\n",
    "    \"\"\"\n",
    "    Função para obter medidas de acurária a partir dos dados de projeção e teste\n",
    "    \"\"\"\n",
    "    #forecast.reset_index(drop = True, inplace = True)\n",
    "    #test.reset_index(drop = True, inplace = True)\n",
    "    #errors = [(test.iloc[i] - forecast.iloc[i])**2 for i in range(len(test))]\n",
    "    if isinstance(forecast, pd.Series) and isinstance(test, pd.Series):\n",
    "        errors = [(test.iloc[i] - forecast.iloc[i])**2 for i in range(len(test))]\n",
    "    # else:\n",
    "    #     errors = [(test.iloc[i][0] - forecast.iloc[i])**2 for i in range(len(test))]\n",
    "    mae = mean_absolute_error(test, forecast)\n",
    "    mse = mean_squared_error(test, forecast)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = mean_absolute_percentage_error(test, forecast)\n",
    "    # smape\n",
    "    a = np.reshape(test.values, (-1,))\n",
    "    b = np.reshape(forecast.values, (-1,))\n",
    "    smape = np.mean(100*2.0 * np.abs(a - b) / (np.abs(a) + np.abs(b))).item()\n",
    "    # dicionário com as medidas de erro\n",
    "    measures = { \"erro\": sum(errors),\n",
    "                 \"mae\": mae,\n",
    "                 \"mse\": mse,\n",
    "                 \"rmse\": rmse,\n",
    "                 \"mape\": mape,\n",
    "                 \"smape\": smape\n",
    "                }\n",
    "    # arredondamento\n",
    "    # for key, item in measures.items():\n",
    "    #     measures[key] = round(measures[key], 2)\n",
    "    return measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando SKTIME para projetar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df.interpolate(method = \"linear\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_mwmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>4800.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>4899.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>6261.554167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>6733.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>6961.170833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             load_mwmed\n",
       "date                   \n",
       "2000-01-01  4800.650000\n",
       "2000-01-02  4899.800000\n",
       "2000-01-03  6261.554167\n",
       "2000-01-04  6733.741667\n",
       "2000-01-05  6961.170833"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sk = df.asfreq('D')\n",
    "df_sk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 10\n",
    "X, y = train_test_split(df_sk, n_test) # split partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sktime\\utils\\datetime.py:108: FutureWarning: Timestamp.freq is deprecated and will be removed in a future version.\n",
      "  if not hasattr(x, \"freq\") or x.freq is None:\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sktime\\utils\\datetime.py:110: FutureWarning: Timestamp.freq is deprecated and will be removed in a future version.\n",
      "  by *= x.freq\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sktime\\forecasting\\base\\_fh.py:565: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  cutoff = _coerce_to_period(cutoff, freq=cutoff.freqstr)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_mwmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-22</th>\n",
       "      <td>8945.294801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23</th>\n",
       "      <td>11716.222344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-24</th>\n",
       "      <td>12023.280010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-25</th>\n",
       "      <td>12047.558935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-26</th>\n",
       "      <td>11899.052396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>11931.996763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-28</th>\n",
       "      <td>10331.229395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-29</th>\n",
       "      <td>8786.639132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-30</th>\n",
       "      <td>11563.565119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>11801.086979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              load_mwmed\n",
       "2022-05-22   8945.294801\n",
       "2022-05-23  11716.222344\n",
       "2022-05-24  12023.280010\n",
       "2022-05-25  12047.558935\n",
       "2022-05-26  11899.052396\n",
       "2022-05-27  11931.996763\n",
       "2022-05-28  10331.229395\n",
       "2022-05-29   8786.639132\n",
       "2022-05-30  11563.565119\n",
       "2022-05-31  11801.086979"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://towardsdatascience.com/multi-step-time-series-forecasting-with-arima-lightgbm-and-prophet-cc9e3f95dfb0\n",
    "\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.compose import make_reduction, TransformedTargetForecaster\n",
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter, ForecastingGridSearchCV\n",
    "\n",
    "regressor = lgb.LGBMRegressor()\n",
    "forecaster = make_reduction(regressor, window_length=60, strategy=\"recursive\")\n",
    "forecaster.fit(X)   # fit \n",
    "forecaster.predict(fh = [x for x in range(1,n_test + 1)])    # forecast three days ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search for LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "def plot_forecast(series_train, series_test, forecast, forecast_int=None):\n",
    "\n",
    "    mae = mean_absolute_error(series_test, forecast)\n",
    "    mape = mean_absolute_percentage_error(series_test, forecast)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title(f\"MAE: {mae:.2f}, MAPE: {mape:.3f}\", size=18)\n",
    "    series_train.plot(label=\"train\", color=\"b\")\n",
    "    series_test.plot(label=\"test\", color=\"g\")\n",
    "    forecast.index = series_test.index\n",
    "    forecast.plot(label=\"forecast\", color=\"r\")\n",
    "    if forecast_int is not None:\n",
    "        plt.fill_between(\n",
    "            series_test.index,\n",
    "            forecast_int[\"lower\"],\n",
    "            forecast_int[\"upper\"],\n",
    "            alpha=0.2,\n",
    "            color=\"dimgray\",\n",
    "        )\n",
    "    plt.legend(prop={\"size\": 16})\n",
    "    plt.show()\n",
    "\n",
    "    return mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_forecaster():\n",
    "    \n",
    "    # creating forecaster with LightGBM\n",
    "    regressor = lgb.LGBMRegressor()\n",
    "    forecaster = make_reduction(regressor, window_length=5, strategy=\"recursive\")\n",
    "    \n",
    "    return forecaster\n",
    "\n",
    "def grid_serch_forecaster(train, test, forecaster, param_grid):\n",
    "\n",
    "    # Grid search on window_length\n",
    "    cv = ExpandingWindowSplitter(initial_window=int(len(train) * 0.7))\n",
    "    gscv = ForecastingGridSearchCV(\n",
    "        forecaster, strategy=\"refit\", cv=cv, param_grid=param_grid\n",
    "    )\n",
    "    gscv.fit(train)\n",
    "    print(f\"best params: {gscv.best_params_}\")\n",
    "    \n",
    "    # forecasting\n",
    "    fh=np.arange(len(test))+1\n",
    "    y_pred = gscv.predict(fh=fh)\n",
    "    mae, mape = plot_forecast(train, test, y_pred)\n",
    "\n",
    "    return mae, mape\n",
    "    \n",
    "param_grid = {\"window_length\": [5, 10, 15, 20, 25, 30]} # parameter set to be grid searched\n",
    "forecaster = create_forecaster()\n",
    "sun_lgb_mae, sun_lgb_mape = grid_serch_forecaster(X, y, forecaster, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUALMENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df.interpolate(method = \"linear\", inplace = True)\n",
    "values = df.values.tolist()\n",
    "lag = 60 \n",
    "outs = 10\n",
    "data = series_to_supervised(values, n_in = lag, n_out = outs, dropnan=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA DA ÚLTIMA LINHA EM \"data\"\n",
    "df[df.load_mwmed == data[\"var1(t)\"].iloc[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 10\n",
    "train, test = train_test_split(data, n_test)\n",
    "train.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_mwmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-21</th>\n",
       "      <td>10256.970375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              load_mwmed\n",
       "date                    \n",
       "2022-05-21  10256.970375"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA DA ÚLTIMA LINHA EM \"data\"\n",
    "df[df.load_mwmed == train[\"var1(t)\"].iloc[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXEMPLO 1: t+3\n",
    "# ÚLTIMO VALOR EM var1(t+h) DEVE SER O MESMO PARA TODAS ESTIMAÇÕES\n",
    "# PARA VISUALIZAR MELHOR, OLHAR EXCEL \"multistep\" NA PASTA \"DATA\"\n",
    "# response_vars = data.columns[-(outs):]\n",
    "# cols = [x for x in data.columns[:lag]]\n",
    "# h = 3 # t + h model\n",
    "# cols.append(f\"var1(t+{h})\")\n",
    "# data_ = train[cols]\n",
    "# data_ = data_.iloc[:-h, :] # t - h, because we only have data up to T\n",
    "# data_X, data_y = data_.iloc[:, :-1], data_.iloc[:, -1]\n",
    "# model = lgb.LGBMRegressor(objective='regression', n_estimators=1000)\n",
    "# model.fit(data_X, data_y)\n",
    "# teste = train.loc[:, :\"var1(t-1)\"].iloc[-1,:] # uses the last available observations to predict t + h\n",
    "# model.predict([teste])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10285.883913939027\n",
      "8949.101203973765\n",
      "11555.944895477676\n",
      "11577.011322779696\n",
      "12110.284326361201\n",
      "11842.924460430644\n",
      "12272.798204323499\n",
      "9923.401389386623\n",
      "9186.951069300245\n",
      "11158.090977791611\n"
     ]
    }
   ],
   "source": [
    "# FOR LOOP (MELHORAR)\n",
    "response_vars = data.columns[-(outs):]\n",
    "\n",
    "predictions = list()\n",
    "for h, response in enumerate(response_vars):\n",
    "    cols = [x for x in data.columns[:lag]]\n",
    "    if h == 0:\n",
    "        cols.append(\"var1(t)\")\n",
    "        data_ = train[cols]\n",
    "        data_ = data_.iloc[:, :]        \n",
    "    else:\n",
    "        cols.append(f\"var1(t+{h})\")\n",
    "    data_ = train[cols]\n",
    "    nrows = data_.shape[0]\n",
    "    data_ = data_.iloc[:nrows-h, :] \n",
    "    data_X, data_y = data_.iloc[:, :-1], data_.iloc[:, -1]\n",
    "    model = lgb.LGBMRegressor(objective='regression', n_estimators=1000)\n",
    "    model.fit(data_X, data_y)\n",
    "    teste = train.loc[:, :\"var1(t-1)\"].iloc[-1,:] # t + 3 (observado = 12.054,20)\n",
    "    pred = model.predict([teste])[0]\n",
    "    print(pred)\n",
    "    predictions.append((h, pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
